{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Character Sequence to Sequence \n",
    "In this notebook, we'll build a model that takes in a sequence of letters, and outputs a sorted version of that sequence. We'll do that using what we've learned so far about Sequence to Sequence models.\n",
    "\n",
    "<img src=\"images/sequence-to-sequence.jpg\"/>\n",
    "\n",
    "\n",
    "## Dataset \n",
    "\n",
    "The dataset lives in the /data/ folder. At the moment, it is made up of the following files:\n",
    " * **letters_source.txt**: The list of input letter sequences. Each sequence is its own line. \n",
    " * **letters_target.txt**: The list of target sequences we'll use in the training process. Each sequence here is a response to the input sequence in letters_source.txt with the same line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "source_path = 'data/letters_source.txt'\n",
    "target_path = 'data/letters_target.txt'\n",
    "\n",
    "source_sentences = helper.load_data(source_path)\n",
    "target_sentences = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by examining the current state of the dataset. `source_sentences` contains the entire input sequence file as text delimited by newline symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bsaqq',\n",
       " 'npy',\n",
       " 'lbwuj',\n",
       " 'bqv',\n",
       " 'kial',\n",
       " 'tddam',\n",
       " 'edxpjpg',\n",
       " 'nspv',\n",
       " 'huloz',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_sentences` contains the entire output sequence file as text delimited by newline symbols.  Each line corresponds to the line from `source_sentences`.  `target_sentences` contains a sorted characters of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abqqs',\n",
       " 'npy',\n",
       " 'bjluw',\n",
       " 'bqv',\n",
       " 'aikl',\n",
       " 'addmt',\n",
       " 'degjppx',\n",
       " 'npsv',\n",
       " 'hlouz',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "To do anything useful with it, we'll need to turn the characters into a list of integers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source sequence\n",
      "[[27, 16, 20, 25, 25], [11, 23, 15], [18, 27, 14, 29, 7]]\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "[[20, 27, 25, 25, 16], [11, 23, 15], [27, 7, 18, 29, 14]]\n"
     ]
    }
   ],
   "source": [
    "def extract_character_vocab(data):\n",
    "    special_words = ['<pad>', '<unk>', '<s>',  '<\\s>']\n",
    "\n",
    "    set_words = set([character for line in data.split('\\n') for character in line])\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Build int2letter and letter2int dicts\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)\n",
    "target_int_to_letter, target_letter_to_int = extract_character_vocab(target_sentences)\n",
    "\n",
    "# Convert characters to ids\n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<unk>']) for letter in line] for line in source_sentences.split('\\n')]\n",
    "target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<unk>']) for letter in line] for line in target_sentences.split('\\n')]\n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(target_letter_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in the preprocessing stage is to determine the the longest sequence size in the dataset we'll be using, then pad all the sequences to that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length\n",
      "7\n",
      "\n",
      "\n",
      "Input sequence example\n",
      "[[27, 16, 20, 25, 25, 0, 0], [11, 23, 15, 0, 0, 0, 0], [18, 27, 14, 29, 7, 0, 0]]\n",
      "\n",
      "\n",
      "Target sequence example\n",
      "[[20, 27, 25, 25, 16, 0, 0], [11, 23, 15, 0, 0, 0, 0], [27, 7, 18, 29, 14, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_id_sequences(source_ids, source_letter_to_int, target_ids, target_letter_to_int, sequence_length):\n",
    "    new_source_ids = [sentence + [source_letter_to_int['<pad>']] * (sequence_length - len(sentence)) \\\n",
    "                      for sentence in source_ids]\n",
    "    new_target_ids = [sentence + [target_letter_to_int['<pad>']] * (sequence_length - len(sentence)) \\\n",
    "                      for sentence in target_ids]\n",
    "\n",
    "    return new_source_ids, new_target_ids\n",
    "\n",
    "\n",
    "# Use the longest sequence as sequence length\n",
    "sequence_length = max(\n",
    "        [len(sentence) for sentence in source_letter_ids] + [len(sentence) for sentence in target_letter_ids])\n",
    "\n",
    "# Pad all sequences up to sequence length\n",
    "source_ids, target_ids = pad_id_sequences(source_letter_ids, source_letter_to_int, \n",
    "                                          target_letter_ids, target_letter_to_int, sequence_length)\n",
    "\n",
    "print(\"Sequence Length\")\n",
    "print(sequence_length)\n",
    "print(\"\\n\")\n",
    "print(\"Input sequence example\")\n",
    "print(source_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Target sequence example\")\n",
    "print(target_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final shape we need them to be in. We can now proceed to building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "#### Check the Version of TensorFlow\n",
    "This will check to make sure you have the correct version of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 58\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 50\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 13\n",
    "decoding_embedding_size = 13\n",
    "# Learning Rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "targets = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence\n",
    "The decoder is probably the most complex part of this model. We need to declare a decoder for the training phase, and a decoder for the inference/prediction phase. These two decoders will share their parameters (so that all the weights and biases that are set during the training phase can be used when we deploy the model).\n",
    "\n",
    "\n",
    "First, we'll need to define the type of cell we'll be using for our decoder RNNs. We opted for LSTM.\n",
    "\n",
    "Then, we'll need to hookup a fully connected layer to the output of decoder. The output of this layer tells us which word the RNN is choosing to output at each time step.\n",
    "\n",
    "Let's first look at the inference/prediction decoder. It is the one we'll use when we deploy our chatbot to the wild (even though it comes second in the actual code).\n",
    "\n",
    "<img src=\"images/sequence-to-sequence-inference-decoder.png\"/>\n",
    "\n",
    "We'll hand our encoder hidden state to the inference decoder and have it process its output. TensorFlow handles most of the logic for us. We just have to use [`tf.contrib.seq2seq.simple_decoder_fn_inference`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) and supply them with the appropriate inputs.\n",
    "\n",
    "Notice that the inference decoder feeds the output of each time step as an input to the next.\n",
    "\n",
    "As for the training decoder, we can think of it as looking like this:\n",
    "<img src=\"images/sequence-to-sequence-training-decoder.png\"/>\n",
    "\n",
    "The training decoder **does not** feed the output of each time step to the next. Rather, the inputs to the decoder time steps are the target sequence from the training dataset (the orange letters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- Embed the input data using [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence)\n",
    "- Pass the embedded input into a stack of RNNs.  Save the RNN state and ignore the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_vocab_size = len(source_letter_to_int)\n",
    "\n",
    "# Encoder embedding\n",
    "enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "# Encoder\n",
    "enc_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "_, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 7)\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Decoding Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets\n",
      "[[ 0  1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12 13]]\n",
      "\n",
      "\n",
      "Processed Decoding Input\n",
      "[[ 2  0  1  2  3  4  5]\n",
      " [ 2  7  8  9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Process the input we'll feed to the decoder\n",
    "ending = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n",
    "dec_input = tf.concat([tf.fill([batch_size, 1], target_letter_to_int['<s>']), ending], 1)\n",
    "\n",
    "demonstration_outputs = np.reshape(range(batch_size * sequence_length), (batch_size, sequence_length))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Targets\")\n",
    "print(demonstration_outputs[:2])\n",
    "print(\"\\n\")\n",
    "print(\"Processed Decoding Input\")\n",
    "print(sess.run(dec_input, {targets: demonstration_outputs})[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding\n",
    "- Embed the decoding input\n",
    "- Build the decoding RNNs\n",
    "- Build the output layer in the decoding scope, so the weight and bias can be shared between the training and inference decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_vocab_size = len(target_letter_to_int)\n",
    "\n",
    "# Decoder Embedding\n",
    "dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "# Decoder RNNs\n",
    "dec_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    # Output Layer\n",
    "    output_fn = lambda x: tf.contrib.layers.fully_connected(x, target_vocab_size, None, scope=decoding_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder During Training\n",
    "- Build the training decoder using [`tf.contrib.seq2seq.simple_decoder_fn_train`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).\n",
    "- Apply the output layer to the output of the training decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    # Training Decoder\n",
    "    train_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_train(enc_state)\n",
    "    train_pred, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "        dec_cell, train_decoder_fn, dec_embed_input, sequence_length, scope=decoding_scope)\n",
    "    \n",
    "    # Apply output function\n",
    "    train_logits =  output_fn(train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder During Inference\n",
    "- Reuse the weights the biases from the training decoder using [`tf.variable_scope(\"decoding\", reuse=True)`](https://www.tensorflow.org/api_docs/python/tf/variable_scope)\n",
    "- Build the inference decoder using [`tf.contrib.seq2seq.simple_decoder_fn_inference`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).\n",
    " - The output function is applied to the output in this step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoding\", reuse=True) as decoding_scope:\n",
    "    # Inference Decoder\n",
    "    infer_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_inference(\n",
    "        output_fn, enc_state, dec_embeddings, target_letter_to_int['<s>'], target_letter_to_int['<\\s>'], \n",
    "        sequence_length - 1, target_vocab_size)\n",
    "    inference_logits, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(dec_cell, infer_decoder_fn, scope=decoding_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "Our loss function is [`tf.contrib.seq2seq.sequence_loss`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss) provided by the tensor flow seq2seq module. It calculates a weighted cross-entropy loss for the output logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cost = tf.contrib.seq2seq.sequence_loss(\n",
    "    train_logits,\n",
    "    targets,\n",
    "    tf.ones([batch_size, sequence_length]))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "# Gradient Clipping\n",
    "gradients = optimizer.compute_gradients(cost)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train\n",
    "We're now ready to train our model. If you run into OOM (out of memory) issues during training, try to decrease the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/78 - Train Accuracy:  0.033, Validation Accuracy:  0.032, Loss:  3.425\n",
      "Epoch   0 Batch   10/78 - Train Accuracy:  0.402, Validation Accuracy:  0.449, Loss:  3.135\n",
      "Epoch   0 Batch   20/78 - Train Accuracy:  0.478, Validation Accuracy:  0.449, Loss:  2.250\n",
      "Epoch   0 Batch   30/78 - Train Accuracy:  0.442, Validation Accuracy:  0.449, Loss:  2.311\n",
      "Epoch   0 Batch   40/78 - Train Accuracy:  0.434, Validation Accuracy:  0.449, Loss:  2.219\n",
      "Epoch   0 Batch   50/78 - Train Accuracy:  0.360, Validation Accuracy:  0.449, Loss:  2.348\n",
      "Epoch   0 Batch   60/78 - Train Accuracy:  0.469, Validation Accuracy:  0.454, Loss:  1.939\n",
      "Epoch   0 Batch   70/78 - Train Accuracy:  0.439, Validation Accuracy:  0.459, Loss:  2.027\n",
      "Epoch   1 Batch    0/78 - Train Accuracy:  0.422, Validation Accuracy:  0.462, Loss:  2.055\n",
      "Epoch   1 Batch   10/78 - Train Accuracy:  0.433, Validation Accuracy:  0.465, Loss:  2.020\n",
      "Epoch   1 Batch   20/78 - Train Accuracy:  0.509, Validation Accuracy:  0.481, Loss:  1.728\n",
      "Epoch   1 Batch   30/78 - Train Accuracy:  0.473, Validation Accuracy:  0.483, Loss:  1.798\n",
      "Epoch   1 Batch   40/78 - Train Accuracy:  0.483, Validation Accuracy:  0.483, Loss:  1.754\n",
      "Epoch   1 Batch   50/78 - Train Accuracy:  0.429, Validation Accuracy:  0.490, Loss:  1.878\n",
      "Epoch   1 Batch   60/78 - Train Accuracy:  0.508, Validation Accuracy:  0.493, Loss:  1.577\n",
      "Epoch   1 Batch   70/78 - Train Accuracy:  0.496, Validation Accuracy:  0.501, Loss:  1.618\n",
      "Epoch   2 Batch    0/78 - Train Accuracy:  0.498, Validation Accuracy:  0.506, Loss:  1.628\n",
      "Epoch   2 Batch   10/78 - Train Accuracy:  0.503, Validation Accuracy:  0.521, Loss:  1.549\n",
      "Epoch   2 Batch   20/78 - Train Accuracy:  0.577, Validation Accuracy:  0.536, Loss:  1.343\n",
      "Epoch   2 Batch   30/78 - Train Accuracy:  0.549, Validation Accuracy:  0.552, Loss:  1.394\n",
      "Epoch   2 Batch   40/78 - Train Accuracy:  0.593, Validation Accuracy:  0.571, Loss:  1.356\n",
      "Epoch   2 Batch   50/78 - Train Accuracy:  0.537, Validation Accuracy:  0.597, Loss:  1.438\n",
      "Epoch   2 Batch   60/78 - Train Accuracy:  0.604, Validation Accuracy:  0.624, Loss:  1.185\n",
      "Epoch   2 Batch   70/78 - Train Accuracy:  0.603, Validation Accuracy:  0.641, Loss:  1.248\n",
      "Epoch   3 Batch    0/78 - Train Accuracy:  0.623, Validation Accuracy:  0.644, Loss:  1.239\n",
      "Epoch   3 Batch   10/78 - Train Accuracy:  0.613, Validation Accuracy:  0.655, Loss:  1.205\n",
      "Epoch   3 Batch   20/78 - Train Accuracy:  0.683, Validation Accuracy:  0.667, Loss:  1.043\n",
      "Epoch   3 Batch   30/78 - Train Accuracy:  0.672, Validation Accuracy:  0.680, Loss:  1.080\n",
      "Epoch   3 Batch   40/78 - Train Accuracy:  0.689, Validation Accuracy:  0.690, Loss:  1.064\n",
      "Epoch   3 Batch   50/78 - Train Accuracy:  0.641, Validation Accuracy:  0.694, Loss:  1.169\n",
      "Epoch   3 Batch   60/78 - Train Accuracy:  0.696, Validation Accuracy:  0.693, Loss:  0.958\n",
      "Epoch   3 Batch   70/78 - Train Accuracy:  0.675, Validation Accuracy:  0.706, Loss:  1.039\n",
      "Epoch   4 Batch    0/78 - Train Accuracy:  0.683, Validation Accuracy:  0.701, Loss:  1.029\n",
      "Epoch   4 Batch   10/78 - Train Accuracy:  0.701, Validation Accuracy:  0.706, Loss:  1.003\n",
      "Epoch   4 Batch   20/78 - Train Accuracy:  0.747, Validation Accuracy:  0.718, Loss:  0.845\n",
      "Epoch   4 Batch   30/78 - Train Accuracy:  0.725, Validation Accuracy:  0.714, Loss:  0.900\n",
      "Epoch   4 Batch   40/78 - Train Accuracy:  0.732, Validation Accuracy:  0.727, Loss:  0.878\n",
      "Epoch   4 Batch   50/78 - Train Accuracy:  0.706, Validation Accuracy:  0.742, Loss:  0.986\n",
      "Epoch   4 Batch   60/78 - Train Accuracy:  0.744, Validation Accuracy:  0.747, Loss:  0.802\n",
      "Epoch   4 Batch   70/78 - Train Accuracy:  0.732, Validation Accuracy:  0.760, Loss:  0.870\n",
      "Epoch   5 Batch    0/78 - Train Accuracy:  0.749, Validation Accuracy:  0.761, Loss:  0.853\n",
      "Epoch   5 Batch   10/78 - Train Accuracy:  0.760, Validation Accuracy:  0.762, Loss:  0.831\n",
      "Epoch   5 Batch   20/78 - Train Accuracy:  0.796, Validation Accuracy:  0.773, Loss:  0.672\n",
      "Epoch   5 Batch   30/78 - Train Accuracy:  0.773, Validation Accuracy:  0.778, Loss:  0.744\n",
      "Epoch   5 Batch   40/78 - Train Accuracy:  0.789, Validation Accuracy:  0.775, Loss:  0.720\n",
      "Epoch   5 Batch   50/78 - Train Accuracy:  0.744, Validation Accuracy:  0.782, Loss:  0.848\n",
      "Epoch   5 Batch   60/78 - Train Accuracy:  0.794, Validation Accuracy:  0.785, Loss:  0.668\n",
      "Epoch   5 Batch   70/78 - Train Accuracy:  0.769, Validation Accuracy:  0.799, Loss:  0.743\n",
      "Epoch   6 Batch    0/78 - Train Accuracy:  0.787, Validation Accuracy:  0.791, Loss:  0.724\n",
      "Epoch   6 Batch   10/78 - Train Accuracy:  0.790, Validation Accuracy:  0.799, Loss:  0.708\n",
      "Epoch   6 Batch   20/78 - Train Accuracy:  0.819, Validation Accuracy:  0.806, Loss:  0.571\n",
      "Epoch   6 Batch   30/78 - Train Accuracy:  0.797, Validation Accuracy:  0.807, Loss:  0.642\n",
      "Epoch   6 Batch   40/78 - Train Accuracy:  0.809, Validation Accuracy:  0.807, Loss:  0.623\n",
      "Epoch   6 Batch   50/78 - Train Accuracy:  0.769, Validation Accuracy:  0.814, Loss:  0.749\n",
      "Epoch   6 Batch   60/78 - Train Accuracy:  0.816, Validation Accuracy:  0.807, Loss:  0.578\n",
      "Epoch   6 Batch   70/78 - Train Accuracy:  0.801, Validation Accuracy:  0.821, Loss:  0.655\n",
      "Epoch   7 Batch    0/78 - Train Accuracy:  0.817, Validation Accuracy:  0.817, Loss:  0.631\n",
      "Epoch   7 Batch   10/78 - Train Accuracy:  0.811, Validation Accuracy:  0.817, Loss:  0.619\n",
      "Epoch   7 Batch   20/78 - Train Accuracy:  0.831, Validation Accuracy:  0.825, Loss:  0.493\n",
      "Epoch   7 Batch   30/78 - Train Accuracy:  0.826, Validation Accuracy:  0.826, Loss:  0.565\n",
      "Epoch   7 Batch   40/78 - Train Accuracy:  0.833, Validation Accuracy:  0.830, Loss:  0.545\n",
      "Epoch   7 Batch   50/78 - Train Accuracy:  0.791, Validation Accuracy:  0.834, Loss:  0.665\n",
      "Epoch   7 Batch   60/78 - Train Accuracy:  0.843, Validation Accuracy:  0.821, Loss:  0.503\n",
      "Epoch   7 Batch   70/78 - Train Accuracy:  0.810, Validation Accuracy:  0.836, Loss:  0.581\n",
      "Epoch   8 Batch    0/78 - Train Accuracy:  0.835, Validation Accuracy:  0.837, Loss:  0.550\n",
      "Epoch   8 Batch   10/78 - Train Accuracy:  0.829, Validation Accuracy:  0.833, Loss:  0.542\n",
      "Epoch   8 Batch   20/78 - Train Accuracy:  0.860, Validation Accuracy:  0.846, Loss:  0.426\n",
      "Epoch   8 Batch   30/78 - Train Accuracy:  0.847, Validation Accuracy:  0.849, Loss:  0.492\n",
      "Epoch   8 Batch   40/78 - Train Accuracy:  0.854, Validation Accuracy:  0.843, Loss:  0.480\n",
      "Epoch   8 Batch   50/78 - Train Accuracy:  0.820, Validation Accuracy:  0.849, Loss:  0.596\n",
      "Epoch   8 Batch   60/78 - Train Accuracy:  0.862, Validation Accuracy:  0.849, Loss:  0.444\n",
      "Epoch   8 Batch   70/78 - Train Accuracy:  0.833, Validation Accuracy:  0.854, Loss:  0.519\n",
      "Epoch   9 Batch    0/78 - Train Accuracy:  0.848, Validation Accuracy:  0.847, Loss:  0.482\n",
      "Epoch   9 Batch   10/78 - Train Accuracy:  0.855, Validation Accuracy:  0.850, Loss:  0.475\n",
      "Epoch   9 Batch   20/78 - Train Accuracy:  0.887, Validation Accuracy:  0.856, Loss:  0.368\n",
      "Epoch   9 Batch   30/78 - Train Accuracy:  0.872, Validation Accuracy:  0.859, Loss:  0.429\n",
      "Epoch   9 Batch   40/78 - Train Accuracy:  0.873, Validation Accuracy:  0.855, Loss:  0.417\n",
      "Epoch   9 Batch   50/78 - Train Accuracy:  0.834, Validation Accuracy:  0.860, Loss:  0.521\n",
      "Epoch   9 Batch   60/78 - Train Accuracy:  0.869, Validation Accuracy:  0.864, Loss:  0.391\n",
      "Epoch   9 Batch   70/78 - Train Accuracy:  0.848, Validation Accuracy:  0.864, Loss:  0.458\n",
      "Epoch  10 Batch    0/78 - Train Accuracy:  0.867, Validation Accuracy:  0.866, Loss:  0.418\n",
      "Epoch  10 Batch   10/78 - Train Accuracy:  0.866, Validation Accuracy:  0.864, Loss:  0.415\n",
      "Epoch  10 Batch   20/78 - Train Accuracy:  0.910, Validation Accuracy:  0.869, Loss:  0.316\n",
      "Epoch  10 Batch   30/78 - Train Accuracy:  0.887, Validation Accuracy:  0.873, Loss:  0.371\n",
      "Epoch  10 Batch   40/78 - Train Accuracy:  0.892, Validation Accuracy:  0.868, Loss:  0.362\n",
      "Epoch  10 Batch   50/78 - Train Accuracy:  0.844, Validation Accuracy:  0.868, Loss:  0.450\n",
      "Epoch  10 Batch   60/78 - Train Accuracy:  0.887, Validation Accuracy:  0.878, Loss:  0.337\n",
      "Epoch  10 Batch   70/78 - Train Accuracy:  0.864, Validation Accuracy:  0.878, Loss:  0.399\n",
      "Epoch  11 Batch    0/78 - Train Accuracy:  0.884, Validation Accuracy:  0.876, Loss:  0.366\n",
      "Epoch  11 Batch   10/78 - Train Accuracy:  0.868, Validation Accuracy:  0.876, Loss:  0.367\n",
      "Epoch  11 Batch   20/78 - Train Accuracy:  0.932, Validation Accuracy:  0.883, Loss:  0.274\n",
      "Epoch  11 Batch   30/78 - Train Accuracy:  0.893, Validation Accuracy:  0.884, Loss:  0.323\n",
      "Epoch  11 Batch   40/78 - Train Accuracy:  0.904, Validation Accuracy:  0.871, Loss:  0.314\n",
      "Epoch  11 Batch   50/78 - Train Accuracy:  0.862, Validation Accuracy:  0.877, Loss:  0.394\n",
      "Epoch  11 Batch   60/78 - Train Accuracy:  0.903, Validation Accuracy:  0.884, Loss:  0.290\n",
      "Epoch  11 Batch   70/78 - Train Accuracy:  0.883, Validation Accuracy:  0.891, Loss:  0.352\n",
      "Epoch  12 Batch    0/78 - Train Accuracy:  0.898, Validation Accuracy:  0.891, Loss:  0.328\n",
      "Epoch  12 Batch   10/78 - Train Accuracy:  0.892, Validation Accuracy:  0.891, Loss:  0.315\n",
      "Epoch  12 Batch   20/78 - Train Accuracy:  0.935, Validation Accuracy:  0.885, Loss:  0.238\n",
      "Epoch  12 Batch   30/78 - Train Accuracy:  0.908, Validation Accuracy:  0.892, Loss:  0.285\n",
      "Epoch  12 Batch   40/78 - Train Accuracy:  0.911, Validation Accuracy:  0.892, Loss:  0.274\n",
      "Epoch  12 Batch   50/78 - Train Accuracy:  0.869, Validation Accuracy:  0.893, Loss:  0.350\n",
      "Epoch  12 Batch   60/78 - Train Accuracy:  0.905, Validation Accuracy:  0.883, Loss:  0.253\n",
      "Epoch  12 Batch   70/78 - Train Accuracy:  0.891, Validation Accuracy:  0.910, Loss:  0.309\n",
      "Epoch  13 Batch    0/78 - Train Accuracy:  0.903, Validation Accuracy:  0.900, Loss:  0.284\n",
      "Epoch  13 Batch   10/78 - Train Accuracy:  0.894, Validation Accuracy:  0.895, Loss:  0.278\n",
      "Epoch  13 Batch   20/78 - Train Accuracy:  0.936, Validation Accuracy:  0.893, Loss:  0.206\n",
      "Epoch  13 Batch   30/78 - Train Accuracy:  0.917, Validation Accuracy:  0.904, Loss:  0.250\n",
      "Epoch  13 Batch   40/78 - Train Accuracy:  0.922, Validation Accuracy:  0.898, Loss:  0.240\n",
      "Epoch  13 Batch   50/78 - Train Accuracy:  0.879, Validation Accuracy:  0.896, Loss:  0.308\n",
      "Epoch  13 Batch   60/78 - Train Accuracy:  0.926, Validation Accuracy:  0.904, Loss:  0.221\n",
      "Epoch  13 Batch   70/78 - Train Accuracy:  0.893, Validation Accuracy:  0.917, Loss:  0.275\n",
      "Epoch  14 Batch    0/78 - Train Accuracy:  0.916, Validation Accuracy:  0.907, Loss:  0.251\n",
      "Epoch  14 Batch   10/78 - Train Accuracy:  0.910, Validation Accuracy:  0.898, Loss:  0.248\n",
      "Epoch  14 Batch   20/78 - Train Accuracy:  0.943, Validation Accuracy:  0.906, Loss:  0.178\n",
      "Epoch  14 Batch   30/78 - Train Accuracy:  0.917, Validation Accuracy:  0.914, Loss:  0.219\n",
      "Epoch  14 Batch   40/78 - Train Accuracy:  0.926, Validation Accuracy:  0.907, Loss:  0.210\n",
      "Epoch  14 Batch   50/78 - Train Accuracy:  0.896, Validation Accuracy:  0.900, Loss:  0.272\n",
      "Epoch  14 Batch   60/78 - Train Accuracy:  0.933, Validation Accuracy:  0.904, Loss:  0.195\n",
      "Epoch  14 Batch   70/78 - Train Accuracy:  0.901, Validation Accuracy:  0.917, Loss:  0.245\n",
      "Epoch  15 Batch    0/78 - Train Accuracy:  0.917, Validation Accuracy:  0.912, Loss:  0.224\n",
      "Epoch  15 Batch   10/78 - Train Accuracy:  0.910, Validation Accuracy:  0.914, Loss:  0.222\n",
      "Epoch  15 Batch   20/78 - Train Accuracy:  0.953, Validation Accuracy:  0.912, Loss:  0.155\n",
      "Epoch  15 Batch   30/78 - Train Accuracy:  0.924, Validation Accuracy:  0.920, Loss:  0.193\n",
      "Epoch  15 Batch   40/78 - Train Accuracy:  0.933, Validation Accuracy:  0.911, Loss:  0.185\n",
      "Epoch  15 Batch   50/78 - Train Accuracy:  0.911, Validation Accuracy:  0.911, Loss:  0.242\n",
      "Epoch  15 Batch   60/78 - Train Accuracy:  0.935, Validation Accuracy:  0.908, Loss:  0.172\n",
      "Epoch  15 Batch   70/78 - Train Accuracy:  0.914, Validation Accuracy:  0.911, Loss:  0.221\n",
      "Epoch  16 Batch    0/78 - Train Accuracy:  0.930, Validation Accuracy:  0.920, Loss:  0.200\n",
      "Epoch  16 Batch   10/78 - Train Accuracy:  0.912, Validation Accuracy:  0.920, Loss:  0.198\n",
      "Epoch  16 Batch   20/78 - Train Accuracy:  0.960, Validation Accuracy:  0.917, Loss:  0.136\n",
      "Epoch  16 Batch   30/78 - Train Accuracy:  0.931, Validation Accuracy:  0.921, Loss:  0.171\n",
      "Epoch  16 Batch   40/78 - Train Accuracy:  0.939, Validation Accuracy:  0.919, Loss:  0.162\n",
      "Epoch  16 Batch   50/78 - Train Accuracy:  0.914, Validation Accuracy:  0.915, Loss:  0.218\n",
      "Epoch  16 Batch   60/78 - Train Accuracy:  0.939, Validation Accuracy:  0.916, Loss:  0.151\n",
      "Epoch  16 Batch   70/78 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  0.204\n",
      "Epoch  17 Batch    0/78 - Train Accuracy:  0.932, Validation Accuracy:  0.924, Loss:  0.178\n",
      "Epoch  17 Batch   10/78 - Train Accuracy:  0.916, Validation Accuracy:  0.920, Loss:  0.175\n",
      "Epoch  17 Batch   20/78 - Train Accuracy:  0.964, Validation Accuracy:  0.927, Loss:  0.120\n",
      "Epoch  17 Batch   30/78 - Train Accuracy:  0.939, Validation Accuracy:  0.930, Loss:  0.152\n",
      "Epoch  17 Batch   40/78 - Train Accuracy:  0.949, Validation Accuracy:  0.917, Loss:  0.143\n",
      "Epoch  17 Batch   50/78 - Train Accuracy:  0.919, Validation Accuracy:  0.922, Loss:  0.191\n",
      "Epoch  17 Batch   60/78 - Train Accuracy:  0.948, Validation Accuracy:  0.925, Loss:  0.136\n",
      "Epoch  17 Batch   70/78 - Train Accuracy:  0.916, Validation Accuracy:  0.908, Loss:  0.171\n",
      "Epoch  18 Batch    0/78 - Train Accuracy:  0.935, Validation Accuracy:  0.926, Loss:  0.162\n",
      "Epoch  18 Batch   10/78 - Train Accuracy:  0.925, Validation Accuracy:  0.920, Loss:  0.162\n",
      "Epoch  18 Batch   20/78 - Train Accuracy:  0.968, Validation Accuracy:  0.932, Loss:  0.105\n",
      "Epoch  18 Batch   30/78 - Train Accuracy:  0.950, Validation Accuracy:  0.934, Loss:  0.136\n",
      "Epoch  18 Batch   40/78 - Train Accuracy:  0.958, Validation Accuracy:  0.921, Loss:  0.127\n",
      "Epoch  18 Batch   50/78 - Train Accuracy:  0.929, Validation Accuracy:  0.932, Loss:  0.168\n",
      "Epoch  18 Batch   60/78 - Train Accuracy:  0.956, Validation Accuracy:  0.933, Loss:  0.123\n",
      "Epoch  18 Batch   70/78 - Train Accuracy:  0.926, Validation Accuracy:  0.925, Loss:  0.152\n",
      "Epoch  19 Batch    0/78 - Train Accuracy:  0.931, Validation Accuracy:  0.914, Loss:  0.141\n",
      "Epoch  19 Batch   10/78 - Train Accuracy:  0.935, Validation Accuracy:  0.925, Loss:  0.158\n",
      "Epoch  19 Batch   20/78 - Train Accuracy:  0.969, Validation Accuracy:  0.929, Loss:  0.098\n",
      "Epoch  19 Batch   30/78 - Train Accuracy:  0.958, Validation Accuracy:  0.939, Loss:  0.123\n",
      "Epoch  19 Batch   40/78 - Train Accuracy:  0.962, Validation Accuracy:  0.926, Loss:  0.113\n",
      "Epoch  19 Batch   50/78 - Train Accuracy:  0.933, Validation Accuracy:  0.930, Loss:  0.150\n",
      "Epoch  19 Batch   60/78 - Train Accuracy:  0.961, Validation Accuracy:  0.931, Loss:  0.111\n",
      "Epoch  19 Batch   70/78 - Train Accuracy:  0.923, Validation Accuracy:  0.926, Loss:  0.143\n",
      "Epoch  20 Batch    0/78 - Train Accuracy:  0.951, Validation Accuracy:  0.941, Loss:  0.130\n",
      "Epoch  20 Batch   10/78 - Train Accuracy:  0.941, Validation Accuracy:  0.938, Loss:  0.123\n",
      "Epoch  20 Batch   20/78 - Train Accuracy:  0.978, Validation Accuracy:  0.942, Loss:  0.082\n",
      "Epoch  20 Batch   30/78 - Train Accuracy:  0.969, Validation Accuracy:  0.940, Loss:  0.110\n",
      "Epoch  20 Batch   40/78 - Train Accuracy:  0.968, Validation Accuracy:  0.935, Loss:  0.101\n",
      "Epoch  20 Batch   50/78 - Train Accuracy:  0.939, Validation Accuracy:  0.935, Loss:  0.133\n",
      "Epoch  20 Batch   60/78 - Train Accuracy:  0.971, Validation Accuracy:  0.943, Loss:  0.099\n",
      "Epoch  20 Batch   70/78 - Train Accuracy:  0.926, Validation Accuracy:  0.944, Loss:  0.121\n",
      "Epoch  21 Batch    0/78 - Train Accuracy:  0.953, Validation Accuracy:  0.948, Loss:  0.118\n",
      "Epoch  21 Batch   10/78 - Train Accuracy:  0.949, Validation Accuracy:  0.941, Loss:  0.109\n",
      "Epoch  21 Batch   20/78 - Train Accuracy:  0.975, Validation Accuracy:  0.948, Loss:  0.072\n",
      "Epoch  21 Batch   30/78 - Train Accuracy:  0.970, Validation Accuracy:  0.945, Loss:  0.098\n",
      "Epoch  21 Batch   40/78 - Train Accuracy:  0.968, Validation Accuracy:  0.941, Loss:  0.089\n",
      "Epoch  21 Batch   50/78 - Train Accuracy:  0.942, Validation Accuracy:  0.941, Loss:  0.119\n",
      "Epoch  21 Batch   60/78 - Train Accuracy:  0.972, Validation Accuracy:  0.942, Loss:  0.089\n",
      "Epoch  21 Batch   70/78 - Train Accuracy:  0.927, Validation Accuracy:  0.946, Loss:  0.107\n",
      "Epoch  22 Batch    0/78 - Train Accuracy:  0.955, Validation Accuracy:  0.945, Loss:  0.106\n",
      "Epoch  22 Batch   10/78 - Train Accuracy:  0.951, Validation Accuracy:  0.938, Loss:  0.097\n",
      "Epoch  22 Batch   20/78 - Train Accuracy:  0.975, Validation Accuracy:  0.956, Loss:  0.064\n",
      "Epoch  22 Batch   30/78 - Train Accuracy:  0.967, Validation Accuracy:  0.949, Loss:  0.087\n",
      "Epoch  22 Batch   40/78 - Train Accuracy:  0.975, Validation Accuracy:  0.940, Loss:  0.079\n",
      "Epoch  22 Batch   50/78 - Train Accuracy:  0.946, Validation Accuracy:  0.951, Loss:  0.107\n",
      "Epoch  22 Batch   60/78 - Train Accuracy:  0.972, Validation Accuracy:  0.942, Loss:  0.082\n",
      "Epoch  22 Batch   70/78 - Train Accuracy:  0.941, Validation Accuracy:  0.954, Loss:  0.097\n",
      "Epoch  23 Batch    0/78 - Train Accuracy:  0.960, Validation Accuracy:  0.945, Loss:  0.096\n",
      "Epoch  23 Batch   10/78 - Train Accuracy:  0.962, Validation Accuracy:  0.940, Loss:  0.087\n",
      "Epoch  23 Batch   20/78 - Train Accuracy:  0.981, Validation Accuracy:  0.952, Loss:  0.057\n",
      "Epoch  23 Batch   30/78 - Train Accuracy:  0.967, Validation Accuracy:  0.952, Loss:  0.079\n",
      "Epoch  23 Batch   40/78 - Train Accuracy:  0.975, Validation Accuracy:  0.940, Loss:  0.071\n",
      "Epoch  23 Batch   50/78 - Train Accuracy:  0.953, Validation Accuracy:  0.952, Loss:  0.098\n",
      "Epoch  23 Batch   60/78 - Train Accuracy:  0.974, Validation Accuracy:  0.952, Loss:  0.077\n",
      "Epoch  23 Batch   70/78 - Train Accuracy:  0.949, Validation Accuracy:  0.955, Loss:  0.091\n",
      "Epoch  24 Batch    0/78 - Train Accuracy:  0.968, Validation Accuracy:  0.945, Loss:  0.090\n",
      "Epoch  24 Batch   10/78 - Train Accuracy:  0.959, Validation Accuracy:  0.941, Loss:  0.083\n",
      "Epoch  24 Batch   20/78 - Train Accuracy:  0.987, Validation Accuracy:  0.945, Loss:  0.052\n",
      "Epoch  24 Batch   30/78 - Train Accuracy:  0.970, Validation Accuracy:  0.952, Loss:  0.071\n",
      "Epoch  24 Batch   40/78 - Train Accuracy:  0.975, Validation Accuracy:  0.944, Loss:  0.065\n",
      "Epoch  24 Batch   50/78 - Train Accuracy:  0.952, Validation Accuracy:  0.954, Loss:  0.091\n",
      "Epoch  24 Batch   60/78 - Train Accuracy:  0.975, Validation Accuracy:  0.952, Loss:  0.074\n",
      "Epoch  24 Batch   70/78 - Train Accuracy:  0.951, Validation Accuracy:  0.951, Loss:  0.084\n",
      "Epoch  25 Batch    0/78 - Train Accuracy:  0.962, Validation Accuracy:  0.943, Loss:  0.083\n",
      "Epoch  25 Batch   10/78 - Train Accuracy:  0.977, Validation Accuracy:  0.950, Loss:  0.072\n",
      "Epoch  25 Batch   20/78 - Train Accuracy:  0.984, Validation Accuracy:  0.952, Loss:  0.046\n",
      "Epoch  25 Batch   30/78 - Train Accuracy:  0.977, Validation Accuracy:  0.951, Loss:  0.065\n",
      "Epoch  25 Batch   40/78 - Train Accuracy:  0.974, Validation Accuracy:  0.944, Loss:  0.058\n",
      "Epoch  25 Batch   50/78 - Train Accuracy:  0.968, Validation Accuracy:  0.953, Loss:  0.082\n",
      "Epoch  25 Batch   60/78 - Train Accuracy:  0.975, Validation Accuracy:  0.952, Loss:  0.062\n",
      "Epoch  25 Batch   70/78 - Train Accuracy:  0.964, Validation Accuracy:  0.951, Loss:  0.075\n",
      "Epoch  26 Batch    0/78 - Train Accuracy:  0.963, Validation Accuracy:  0.939, Loss:  0.081\n",
      "Epoch  26 Batch   10/78 - Train Accuracy:  0.983, Validation Accuracy:  0.952, Loss:  0.065\n",
      "Epoch  26 Batch   20/78 - Train Accuracy:  0.987, Validation Accuracy:  0.950, Loss:  0.042\n",
      "Epoch  26 Batch   30/78 - Train Accuracy:  0.977, Validation Accuracy:  0.951, Loss:  0.060\n",
      "Epoch  26 Batch   40/78 - Train Accuracy:  0.977, Validation Accuracy:  0.941, Loss:  0.054\n",
      "Epoch  26 Batch   50/78 - Train Accuracy:  0.970, Validation Accuracy:  0.953, Loss:  0.073\n",
      "Epoch  26 Batch   60/78 - Train Accuracy:  0.974, Validation Accuracy:  0.955, Loss:  0.056\n",
      "Epoch  26 Batch   70/78 - Train Accuracy:  0.973, Validation Accuracy:  0.955, Loss:  0.067\n",
      "Epoch  27 Batch    0/78 - Train Accuracy:  0.965, Validation Accuracy:  0.942, Loss:  0.071\n",
      "Epoch  27 Batch   10/78 - Train Accuracy:  0.982, Validation Accuracy:  0.953, Loss:  0.059\n",
      "Epoch  27 Batch   20/78 - Train Accuracy:  0.991, Validation Accuracy:  0.950, Loss:  0.038\n",
      "Epoch  27 Batch   30/78 - Train Accuracy:  0.982, Validation Accuracy:  0.951, Loss:  0.055\n",
      "Epoch  27 Batch   40/78 - Train Accuracy:  0.978, Validation Accuracy:  0.941, Loss:  0.049\n",
      "Epoch  27 Batch   50/78 - Train Accuracy:  0.968, Validation Accuracy:  0.953, Loss:  0.068\n",
      "Epoch  27 Batch   60/78 - Train Accuracy:  0.974, Validation Accuracy:  0.955, Loss:  0.053\n",
      "Epoch  27 Batch   70/78 - Train Accuracy:  0.980, Validation Accuracy:  0.954, Loss:  0.061\n",
      "Epoch  28 Batch    0/78 - Train Accuracy:  0.967, Validation Accuracy:  0.945, Loss:  0.062\n",
      "Epoch  28 Batch   10/78 - Train Accuracy:  0.980, Validation Accuracy:  0.959, Loss:  0.054\n",
      "Epoch  28 Batch   20/78 - Train Accuracy:  0.993, Validation Accuracy:  0.952, Loss:  0.034\n",
      "Epoch  28 Batch   30/78 - Train Accuracy:  0.981, Validation Accuracy:  0.951, Loss:  0.051\n",
      "Epoch  28 Batch   40/78 - Train Accuracy:  0.981, Validation Accuracy:  0.948, Loss:  0.045\n",
      "Epoch  28 Batch   50/78 - Train Accuracy:  0.967, Validation Accuracy:  0.955, Loss:  0.064\n",
      "Epoch  28 Batch   60/78 - Train Accuracy:  0.974, Validation Accuracy:  0.960, Loss:  0.051\n",
      "Epoch  28 Batch   70/78 - Train Accuracy:  0.983, Validation Accuracy:  0.953, Loss:  0.055\n",
      "Epoch  29 Batch    0/78 - Train Accuracy:  0.970, Validation Accuracy:  0.948, Loss:  0.057\n",
      "Epoch  29 Batch   10/78 - Train Accuracy:  0.983, Validation Accuracy:  0.961, Loss:  0.049\n",
      "Epoch  29 Batch   20/78 - Train Accuracy:  0.993, Validation Accuracy:  0.961, Loss:  0.031\n",
      "Epoch  29 Batch   30/78 - Train Accuracy:  0.981, Validation Accuracy:  0.953, Loss:  0.048\n",
      "Epoch  29 Batch   40/78 - Train Accuracy:  0.982, Validation Accuracy:  0.955, Loss:  0.041\n",
      "Epoch  29 Batch   50/78 - Train Accuracy:  0.970, Validation Accuracy:  0.956, Loss:  0.061\n",
      "Epoch  29 Batch   60/78 - Train Accuracy:  0.973, Validation Accuracy:  0.953, Loss:  0.047\n",
      "Epoch  29 Batch   70/78 - Train Accuracy:  0.982, Validation Accuracy:  0.955, Loss:  0.051\n",
      "Epoch  30 Batch    0/78 - Train Accuracy:  0.970, Validation Accuracy:  0.948, Loss:  0.053\n",
      "Epoch  30 Batch   10/78 - Train Accuracy:  0.987, Validation Accuracy:  0.960, Loss:  0.044\n",
      "Epoch  30 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.958, Loss:  0.028\n",
      "Epoch  30 Batch   30/78 - Train Accuracy:  0.981, Validation Accuracy:  0.958, Loss:  0.043\n",
      "Epoch  30 Batch   40/78 - Train Accuracy:  0.989, Validation Accuracy:  0.954, Loss:  0.038\n",
      "Epoch  30 Batch   50/78 - Train Accuracy:  0.973, Validation Accuracy:  0.956, Loss:  0.055\n",
      "Epoch  30 Batch   60/78 - Train Accuracy:  0.973, Validation Accuracy:  0.955, Loss:  0.044\n",
      "Epoch  30 Batch   70/78 - Train Accuracy:  0.982, Validation Accuracy:  0.955, Loss:  0.046\n",
      "Epoch  31 Batch    0/78 - Train Accuracy:  0.973, Validation Accuracy:  0.955, Loss:  0.048\n",
      "Epoch  31 Batch   10/78 - Train Accuracy:  0.987, Validation Accuracy:  0.960, Loss:  0.043\n",
      "Epoch  31 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.956, Loss:  0.026\n",
      "Epoch  31 Batch   30/78 - Train Accuracy:  0.984, Validation Accuracy:  0.958, Loss:  0.040\n",
      "Epoch  31 Batch   40/78 - Train Accuracy:  0.990, Validation Accuracy:  0.961, Loss:  0.036\n",
      "Epoch  31 Batch   50/78 - Train Accuracy:  0.972, Validation Accuracy:  0.951, Loss:  0.050\n",
      "Epoch  31 Batch   60/78 - Train Accuracy:  0.974, Validation Accuracy:  0.962, Loss:  0.045\n",
      "Epoch  31 Batch   70/78 - Train Accuracy:  0.985, Validation Accuracy:  0.953, Loss:  0.041\n",
      "Epoch  32 Batch    0/78 - Train Accuracy:  0.984, Validation Accuracy:  0.958, Loss:  0.046\n",
      "Epoch  32 Batch   10/78 - Train Accuracy:  0.984, Validation Accuracy:  0.950, Loss:  0.043\n",
      "Epoch  32 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.958, Loss:  0.024\n",
      "Epoch  32 Batch   30/78 - Train Accuracy:  0.989, Validation Accuracy:  0.958, Loss:  0.037\n",
      "Epoch  32 Batch   40/78 - Train Accuracy:  0.990, Validation Accuracy:  0.961, Loss:  0.035\n",
      "Epoch  32 Batch   50/78 - Train Accuracy:  0.977, Validation Accuracy:  0.954, Loss:  0.044\n",
      "Epoch  32 Batch   60/78 - Train Accuracy:  0.975, Validation Accuracy:  0.956, Loss:  0.039\n",
      "Epoch  32 Batch   70/78 - Train Accuracy:  0.990, Validation Accuracy:  0.958, Loss:  0.038\n",
      "Epoch  33 Batch    0/78 - Train Accuracy:  0.982, Validation Accuracy:  0.959, Loss:  0.044\n",
      "Epoch  33 Batch   10/78 - Train Accuracy:  0.984, Validation Accuracy:  0.949, Loss:  0.037\n",
      "Epoch  33 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.958, Loss:  0.022\n",
      "Epoch  33 Batch   30/78 - Train Accuracy:  0.988, Validation Accuracy:  0.951, Loss:  0.035\n",
      "Epoch  33 Batch   40/78 - Train Accuracy:  0.990, Validation Accuracy:  0.962, Loss:  0.033\n",
      "Epoch  33 Batch   50/78 - Train Accuracy:  0.978, Validation Accuracy:  0.962, Loss:  0.040\n",
      "Epoch  33 Batch   60/78 - Train Accuracy:  0.978, Validation Accuracy:  0.960, Loss:  0.032\n",
      "Epoch  33 Batch   70/78 - Train Accuracy:  0.994, Validation Accuracy:  0.959, Loss:  0.039\n",
      "Epoch  34 Batch    0/78 - Train Accuracy:  0.983, Validation Accuracy:  0.954, Loss:  0.039\n",
      "Epoch  34 Batch   10/78 - Train Accuracy:  0.996, Validation Accuracy:  0.955, Loss:  0.035\n",
      "Epoch  34 Batch   20/78 - Train Accuracy:  0.997, Validation Accuracy:  0.958, Loss:  0.020\n",
      "Epoch  34 Batch   30/78 - Train Accuracy:  0.988, Validation Accuracy:  0.958, Loss:  0.032\n",
      "Epoch  34 Batch   40/78 - Train Accuracy:  0.991, Validation Accuracy:  0.967, Loss:  0.029\n",
      "Epoch  34 Batch   50/78 - Train Accuracy:  0.982, Validation Accuracy:  0.962, Loss:  0.036\n",
      "Epoch  34 Batch   60/78 - Train Accuracy:  0.982, Validation Accuracy:  0.956, Loss:  0.031\n",
      "Epoch  34 Batch   70/78 - Train Accuracy:  0.998, Validation Accuracy:  0.962, Loss:  0.033\n",
      "Epoch  35 Batch    0/78 - Train Accuracy:  0.990, Validation Accuracy:  0.958, Loss:  0.032\n",
      "Epoch  35 Batch   10/78 - Train Accuracy:  0.996, Validation Accuracy:  0.952, Loss:  0.031\n",
      "Epoch  35 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.962, Loss:  0.021\n",
      "Epoch  35 Batch   30/78 - Train Accuracy:  0.991, Validation Accuracy:  0.960, Loss:  0.028\n",
      "Epoch  35 Batch   40/78 - Train Accuracy:  0.991, Validation Accuracy:  0.961, Loss:  0.036\n",
      "Epoch  35 Batch   50/78 - Train Accuracy:  0.982, Validation Accuracy:  0.956, Loss:  0.038\n",
      "Epoch  35 Batch   60/78 - Train Accuracy:  0.983, Validation Accuracy:  0.953, Loss:  0.034\n",
      "Epoch  35 Batch   70/78 - Train Accuracy:  0.991, Validation Accuracy:  0.960, Loss:  0.036\n",
      "Epoch  36 Batch    0/78 - Train Accuracy:  0.988, Validation Accuracy:  0.956, Loss:  0.034\n",
      "Epoch  36 Batch   10/78 - Train Accuracy:  0.996, Validation Accuracy:  0.953, Loss:  0.031\n",
      "Epoch  36 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.970, Loss:  0.019\n",
      "Epoch  36 Batch   30/78 - Train Accuracy:  0.990, Validation Accuracy:  0.960, Loss:  0.036\n",
      "Epoch  36 Batch   40/78 - Train Accuracy:  0.991, Validation Accuracy:  0.965, Loss:  0.026\n",
      "Epoch  36 Batch   50/78 - Train Accuracy:  0.987, Validation Accuracy:  0.955, Loss:  0.031\n",
      "Epoch  36 Batch   60/78 - Train Accuracy:  0.985, Validation Accuracy:  0.963, Loss:  0.028\n",
      "Epoch  36 Batch   70/78 - Train Accuracy:  0.998, Validation Accuracy:  0.962, Loss:  0.027\n",
      "Epoch  37 Batch    0/78 - Train Accuracy:  0.997, Validation Accuracy:  0.956, Loss:  0.028\n",
      "Epoch  37 Batch   10/78 - Train Accuracy:  0.997, Validation Accuracy:  0.952, Loss:  0.028\n",
      "Epoch  37 Batch   20/78 - Train Accuracy:  0.998, Validation Accuracy:  0.963, Loss:  0.016\n",
      "Epoch  37 Batch   30/78 - Train Accuracy:  0.991, Validation Accuracy:  0.956, Loss:  0.027\n",
      "Epoch  37 Batch   40/78 - Train Accuracy:  0.994, Validation Accuracy:  0.955, Loss:  0.024\n",
      "Epoch  37 Batch   50/78 - Train Accuracy:  0.987, Validation Accuracy:  0.960, Loss:  0.031\n",
      "Epoch  37 Batch   60/78 - Train Accuracy:  0.987, Validation Accuracy:  0.959, Loss:  0.025\n",
      "Epoch  37 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.024\n",
      "Epoch  38 Batch    0/78 - Train Accuracy:  0.997, Validation Accuracy:  0.962, Loss:  0.025\n",
      "Epoch  38 Batch   10/78 - Train Accuracy:  0.997, Validation Accuracy:  0.956, Loss:  0.024\n",
      "Epoch  38 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.013\n",
      "Epoch  38 Batch   30/78 - Train Accuracy:  0.991, Validation Accuracy:  0.958, Loss:  0.023\n",
      "Epoch  38 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.962, Loss:  0.020\n",
      "Epoch  38 Batch   50/78 - Train Accuracy:  0.992, Validation Accuracy:  0.959, Loss:  0.026\n",
      "Epoch  38 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.965, Loss:  0.023\n",
      "Epoch  38 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.969, Loss:  0.022\n",
      "Epoch  39 Batch    0/78 - Train Accuracy:  0.996, Validation Accuracy:  0.962, Loss:  0.023\n",
      "Epoch  39 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.960, Loss:  0.022\n",
      "Epoch  39 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.012\n",
      "Epoch  39 Batch   30/78 - Train Accuracy:  0.997, Validation Accuracy:  0.970, Loss:  0.020\n",
      "Epoch  39 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.962, Loss:  0.019\n",
      "Epoch  39 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.962, Loss:  0.024\n",
      "Epoch  39 Batch   60/78 - Train Accuracy:  0.992, Validation Accuracy:  0.968, Loss:  0.022\n",
      "Epoch  39 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.969, Loss:  0.020\n",
      "Epoch  40 Batch    0/78 - Train Accuracy:  0.996, Validation Accuracy:  0.960, Loss:  0.021\n",
      "Epoch  40 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.963, Loss:  0.020\n",
      "Epoch  40 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.011\n",
      "Epoch  40 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.019\n",
      "Epoch  40 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.962, Loss:  0.017\n",
      "Epoch  40 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.961, Loss:  0.022\n",
      "Epoch  40 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.967, Loss:  0.020\n",
      "Epoch  40 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.969, Loss:  0.019\n",
      "Epoch  41 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.965, Loss:  0.020\n",
      "Epoch  41 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.963, Loss:  0.019\n",
      "Epoch  41 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.011\n",
      "Epoch  41 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.017\n",
      "Epoch  41 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.962, Loss:  0.016\n",
      "Epoch  41 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.967, Loss:  0.021\n",
      "Epoch  41 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.971, Loss:  0.019\n",
      "Epoch  41 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.018\n",
      "Epoch  42 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.018\n",
      "Epoch  42 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.017\n",
      "Epoch  42 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.010\n",
      "Epoch  42 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.016\n",
      "Epoch  42 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.968, Loss:  0.015\n",
      "Epoch  42 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.970, Loss:  0.020\n",
      "Epoch  42 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.971, Loss:  0.018\n",
      "Epoch  42 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.016\n",
      "Epoch  43 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.017\n",
      "Epoch  43 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.016\n",
      "Epoch  43 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.973, Loss:  0.009\n",
      "Epoch  43 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.015\n",
      "Epoch  43 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.973, Loss:  0.014\n",
      "Epoch  43 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.970, Loss:  0.019\n",
      "Epoch  43 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.970, Loss:  0.017\n",
      "Epoch  43 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.015\n",
      "Epoch  44 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.016\n",
      "Epoch  44 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.015\n",
      "Epoch  44 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.973, Loss:  0.008\n",
      "Epoch  44 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.014\n",
      "Epoch  44 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.973, Loss:  0.013\n",
      "Epoch  44 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.970, Loss:  0.017\n",
      "Epoch  44 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.970, Loss:  0.015\n",
      "Epoch  44 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.977, Loss:  0.014\n",
      "Epoch  45 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.968, Loss:  0.015\n",
      "Epoch  45 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.014\n",
      "Epoch  45 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.973, Loss:  0.008\n",
      "Epoch  45 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.013\n",
      "Epoch  45 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.979, Loss:  0.012\n",
      "Epoch  45 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.970, Loss:  0.017\n",
      "Epoch  45 Batch   60/78 - Train Accuracy:  0.991, Validation Accuracy:  0.969, Loss:  0.014\n",
      "Epoch  45 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.977, Loss:  0.013\n",
      "Epoch  46 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.014\n",
      "Epoch  46 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.013\n",
      "Epoch  46 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.973, Loss:  0.007\n",
      "Epoch  46 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.013\n",
      "Epoch  46 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.978, Loss:  0.011\n",
      "Epoch  46 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.965, Loss:  0.016\n",
      "Epoch  46 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.975, Loss:  0.013\n",
      "Epoch  46 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.977, Loss:  0.012\n",
      "Epoch  47 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.013\n",
      "Epoch  47 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.012\n",
      "Epoch  47 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.972, Loss:  0.007\n",
      "Epoch  47 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.012\n",
      "Epoch  47 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.978, Loss:  0.010\n",
      "Epoch  47 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.965, Loss:  0.015\n",
      "Epoch  47 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.977, Loss:  0.013\n",
      "Epoch  47 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.977, Loss:  0.011\n",
      "Epoch  48 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.012\n",
      "Epoch  48 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.011\n",
      "Epoch  48 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.006\n",
      "Epoch  48 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.011\n",
      "Epoch  48 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.978, Loss:  0.009\n",
      "Epoch  48 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.965, Loss:  0.014\n",
      "Epoch  48 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.012\n",
      "Epoch  48 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.972, Loss:  0.010\n",
      "Epoch  49 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.979, Loss:  0.011\n",
      "Epoch  49 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.971, Loss:  0.010\n",
      "Epoch  49 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.979, Loss:  0.006\n",
      "Epoch  49 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.011\n",
      "Epoch  49 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.009\n",
      "Epoch  49 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.965, Loss:  0.013\n",
      "Epoch  49 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.983, Loss:  0.011\n",
      "Epoch  49 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.977, Loss:  0.010\n",
      "Epoch  50 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.011\n",
      "Epoch  50 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.973, Loss:  0.010\n",
      "Epoch  50 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.978, Loss:  0.005\n",
      "Epoch  50 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.010\n",
      "Epoch  50 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.008\n",
      "Epoch  50 Batch   50/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.013\n",
      "Epoch  50 Batch   60/78 - Train Accuracy:  1.000, Validation Accuracy:  0.970, Loss:  0.012\n",
      "Epoch  50 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.013\n",
      "Epoch  51 Batch    0/78 - Train Accuracy:  0.999, Validation Accuracy:  0.975, Loss:  0.016\n",
      "Epoch  51 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.982, Loss:  0.017\n",
      "Epoch  51 Batch   20/78 - Train Accuracy:  0.990, Validation Accuracy:  0.961, Loss:  0.027\n",
      "Epoch  51 Batch   30/78 - Train Accuracy:  0.973, Validation Accuracy:  0.953, Loss:  0.041\n",
      "Epoch  51 Batch   40/78 - Train Accuracy:  0.952, Validation Accuracy:  0.927, Loss:  0.048\n",
      "Epoch  51 Batch   50/78 - Train Accuracy:  0.974, Validation Accuracy:  0.934, Loss:  0.056\n",
      "Epoch  51 Batch   60/78 - Train Accuracy:  0.982, Validation Accuracy:  0.951, Loss:  0.026\n",
      "Epoch  51 Batch   70/78 - Train Accuracy:  0.987, Validation Accuracy:  0.968, Loss:  0.025\n",
      "Epoch  52 Batch    0/78 - Train Accuracy:  0.994, Validation Accuracy:  0.970, Loss:  0.019\n",
      "Epoch  52 Batch   10/78 - Train Accuracy:  0.993, Validation Accuracy:  0.964, Loss:  0.022\n",
      "Epoch  52 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.978, Loss:  0.007\n",
      "Epoch  52 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.965, Loss:  0.012\n",
      "Epoch  52 Batch   40/78 - Train Accuracy:  0.996, Validation Accuracy:  0.980, Loss:  0.010\n",
      "Epoch  52 Batch   50/78 - Train Accuracy:  0.989, Validation Accuracy:  0.985, Loss:  0.014\n",
      "Epoch  52 Batch   60/78 - Train Accuracy:  0.990, Validation Accuracy:  0.980, Loss:  0.012\n",
      "Epoch  52 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.985, Loss:  0.011\n",
      "Epoch  53 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.011\n",
      "Epoch  53 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.978, Loss:  0.010\n",
      "Epoch  53 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.006\n",
      "Epoch  53 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.010\n",
      "Epoch  53 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.009\n",
      "Epoch  53 Batch   50/78 - Train Accuracy:  0.996, Validation Accuracy:  0.978, Loss:  0.011\n",
      "Epoch  53 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.981, Loss:  0.010\n",
      "Epoch  53 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.974, Loss:  0.009\n",
      "Epoch  54 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.978, Loss:  0.009\n",
      "Epoch  54 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.978, Loss:  0.009\n",
      "Epoch  54 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.005\n",
      "Epoch  54 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.008\n",
      "Epoch  54 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.007\n",
      "Epoch  54 Batch   50/78 - Train Accuracy:  0.994, Validation Accuracy:  0.978, Loss:  0.010\n",
      "Epoch  54 Batch   60/78 - Train Accuracy:  0.994, Validation Accuracy:  0.983, Loss:  0.009\n",
      "Epoch  54 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.008\n",
      "Epoch  55 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.008\n",
      "Epoch  55 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.007\n",
      "Epoch  55 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.004\n",
      "Epoch  55 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.007\n",
      "Epoch  55 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.006\n",
      "Epoch  55 Batch   50/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.009\n",
      "Epoch  55 Batch   60/78 - Train Accuracy:  1.000, Validation Accuracy:  0.983, Loss:  0.008\n",
      "Epoch  55 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.981, Loss:  0.007\n",
      "Epoch  56 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.008\n",
      "Epoch  56 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.007\n",
      "Epoch  56 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.004\n",
      "Epoch  56 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.006\n",
      "Epoch  56 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.005\n",
      "Epoch  56 Batch   50/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.008\n",
      "Epoch  56 Batch   60/78 - Train Accuracy:  1.000, Validation Accuracy:  0.989, Loss:  0.007\n",
      "Epoch  56 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.983, Loss:  0.007\n",
      "Epoch  57 Batch    0/78 - Train Accuracy:  1.000, Validation Accuracy:  0.982, Loss:  0.007\n",
      "Epoch  57 Batch   10/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.006\n",
      "Epoch  57 Batch   20/78 - Train Accuracy:  1.000, Validation Accuracy:  0.980, Loss:  0.004\n",
      "Epoch  57 Batch   30/78 - Train Accuracy:  1.000, Validation Accuracy:  0.975, Loss:  0.006\n",
      "Epoch  57 Batch   40/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.005\n",
      "Epoch  57 Batch   50/78 - Train Accuracy:  1.000, Validation Accuracy:  0.984, Loss:  0.007\n",
      "Epoch  57 Batch   60/78 - Train Accuracy:  1.000, Validation Accuracy:  0.989, Loss:  0.007\n",
      "Epoch  57 Batch   70/78 - Train Accuracy:  1.000, Validation Accuracy:  0.983, Loss:  0.006\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_source = source_ids[batch_size:]\n",
    "train_target = target_ids[batch_size:]\n",
    "\n",
    "valid_source = source_ids[:batch_size]\n",
    "valid_target = target_ids[:batch_size]\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(\n",
    "            helper.batch_data(train_source, train_target, batch_size)):\n",
    "        _, loss = sess.run(\n",
    "            [train_op, cost],\n",
    "            {input_data: source_batch, targets: target_batch, lr: learning_rate})\n",
    "        batch_train_logits = sess.run(\n",
    "            inference_logits,\n",
    "            {input_data: source_batch})\n",
    "        batch_valid_logits = sess.run(\n",
    "            inference_logits,\n",
    "            {input_data: valid_source})\n",
    "\n",
    "        train_acc = np.mean(np.equal(target_batch, np.argmax(batch_train_logits, 2)))\n",
    "        valid_acc = np.mean(np.equal(valid_target, np.argmax(batch_valid_logits, 2)))\n",
    "        if batch_i % 10 == 0:\n",
    "            print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "              .format(epoch_i, batch_i, len(source_ids) // batch_size, train_acc, valid_acc, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "  Word Ids:      [14, 29, 15, 20, 11, 0, 0]\n",
      "  Input Words: ['w', 'u', 'y', 'a', 'n', '<pad>', '<pad>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [20, 11, 29, 14, 15, 0, 0]\n",
      "  Chatbot Answer Words: ['a', 'n', 'u', 'w', 'y', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'hello'\n",
    "input_sentence = 'wuyan'\n",
    "\n",
    "\n",
    "input_sentence = [source_letter_to_int.get(word, source_letter_to_int['<unk>']) for word in input_sentence.lower()]\n",
    "input_sentence = input_sentence + [0] * (sequence_length - len(input_sentence))\n",
    "batch_shell = np.zeros((batch_size, sequence_length))\n",
    "batch_shell[0] = input_sentence\n",
    "chatbot_logits = sess.run(inference_logits, {input_data: batch_shell})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in input_sentence]))\n",
    "print('  Input Words: {}'.format([source_int_to_letter[i] for i in input_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in np.argmax(chatbot_logits, 1)]))\n",
    "print('  Chatbot Answer Words: {}'.format([target_int_to_letter[i] for i in np.argmax(chatbot_logits, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
